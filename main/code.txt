import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
from colorama import Fore, Style 

data = pd.read_csv('test.csv')

# Check the balance of the dataset
data.columns = data.columns.str.strip()
print(data['loan_status'].value_counts())

data.info()

# checking null values
print(Fore.RED + Style.BRIGHT + "checking null values :- "); print(Style.RESET_ALL)
print(data.isnull().sum())

data.drop('loan_id', axis=1, inplace=True)

#@ Fill missing numerical values with mean
numerical_cols = data.select_dtypes(include=[np.number]).columns
data[numerical_cols] = data[numerical_cols].apply(lambda x: x.fillna(x.mean()))

#@ Fill missing categorical values with mode
categorical_cols = data.select_dtypes(include=['object']).columns
data[categorical_cols] = data[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))

# checking null values
print(data.isnull().sum())

# removing spaces from the columns
for col in data.columns:
    if data[col].dtype == 'object':  # If column is of object type (likely strings)
        data[col] = data[col].str.strip()


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

# Splitting the data into test and train sets
x_train, x_test, y_train, y_test = train_test_split(data.drop('loan_status', axis=1, errors='ignore'), data['loan_status'], test_size=0.2, random_state=42)

# Initialize a dictionary to hold the LabelEncoders for each column
label_encoders = {}

# Check if the column exists before transforming
le_education = LabelEncoder()
x_train['education'] = le_education.fit_transform(x_train['education'])
x_test['education'] = le_education.transform(x_test['education'])
label_encoders['education'] = le_education

le_self_employed = LabelEncoder()
x_train['self_employed'] = le_self_employed.fit_transform(x_train['self_employed'])
x_test['self_employed'] = le_self_employed.transform(x_test['self_employed'])
label_encoders['self_employed'] = le_self_employed

# Encode the target variable separately
le_loan_status = LabelEncoder()
y_train = le_loan_status.fit_transform(y_train)
y_test = le_loan_status.transform(y_test)
label_encoders['loan_status'] = le_loan_status

# Feature Scaling
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)


# checking the enconding
print("Loan Status Encoding:", list(le_loan_status.classes_))

# Print the unique values of y_train and y_test
print("Unique values in y_train:", np.unique(y_train))
print("Unique values in y_test:", np.unique(y_test))


from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier 


logistic_model = LogisticRegression()
support_vector_model = SVC(C = 3)
decision_tree_model = DecisionTreeClassifier()

#!training the models
logistic_model.fit(x_train, y_train)
support_vector_model.fit(x_train, y_train)
decision_tree_model.fit(x_train, y_train)

from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

def calculate_and_plot_roc(model, x_test, y_test, model_name):
    # Calculate the probabilities of the positive class
    if model_name == 'Support Vector Machine':
        y_prob = model.decision_function(x_test)
    else:
        y_prob = model.predict_proba(x_test)[:, 1]

    # Calculate the AUC-ROC
    auc_roc = roc_auc_score(y_test, y_prob)

    # Calculate the ROC curve points
    fpr, tpr, _ = roc_curve(y_test, y_prob)

    # Plot the ROC curve
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_roc:.4f})')

    return auc_roc

# Initialize a dictionary to hold the AUC-ROC scores for each model
auc_roc_scores = {}

# Calculate and plot the ROC curve for each model
auc_roc_scores['Logistic Regression'] = calculate_and_plot_roc(logistic_model, x_test, y_test, 'Logistic Regression')
auc_roc_scores['Support Vector Machine'] = calculate_and_plot_roc(support_vector_model, x_test, y_test, 'Support Vector Machine')
auc_roc_scores['Decision Tree'] = calculate_and_plot_roc(decision_tree_model, x_test, y_test, 'Decision Tree')

# Add the diagonal line to the plot
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

# Find the model with the highest AUC-ROC score
best_model_name = max(auc_roc_scores, key=auc_roc_scores.get)

# Initialize a array to hold the models
models = {'Logistic Regression': logistic_model, 'Support Vector Machine': support_vector_model, 'Decision Tree': decision_tree_model}

# Get the best model from the models dictionary
best_model = models[best_model_name]

print(Fore.GREEN + Style.BRIGHT + f"{best_model_name} has the highest accuracy")